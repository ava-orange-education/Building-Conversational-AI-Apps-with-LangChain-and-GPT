{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Rule-based chatbots (Intents)"
      ],
      "metadata": {
        "id": "wvqqU1eHJ6OL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Jy-Cr8s6pR6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3504ddc-7b19-46d4-ba31-6945503a2d06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sure, what location and date are you interested in?\n"
          ]
        }
      ],
      "source": [
        "# Define intents\n",
        "intents = {\n",
        "    \"greeting\": [\"hi\", \"hello\", \"hey\"],\n",
        "    \"weather\": [\"weather\", \"forecast\"],\n",
        "    \"farewell\": [\"bye\", \"goodbye\", \"see you\"]\n",
        "}\n",
        "\n",
        "# Define entities (optional)\n",
        "entities = {\n",
        "    \"location\": [\"New York\", \"Los Angeles\", \"London\"],\n",
        "    \"date\": [\"today\", \"tomorrow\", \"next week\"]\n",
        "}\n",
        "\n",
        "# Define responses\n",
        "responses = {\n",
        "    \"greeting\": \"Hello! How can I help you?\",\n",
        "    \"weather\": \"Sure, what location and date are you interested in?\",\n",
        "    \"farewell\": \"Goodbye! Have a great day.\"\n",
        "}\n",
        "\n",
        "# Sample user input\n",
        "user_input = \"What's the weather like in New York tomorrow?\"\n",
        "\n",
        "# Detect intent\n",
        "intent = None\n",
        "for key, value in intents.items():\n",
        "    if any(keyword in user_input.lower() for keyword in value):\n",
        "        intent = key\n",
        "        break\n",
        "\n",
        "# Generate response based on intent\n",
        "if intent:\n",
        "    print(responses[intent])\n",
        "else:\n",
        "    print(\"I'm sorry, I didn't understand your request.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Rule-based chatbots (Intent and Entities)"
      ],
      "metadata": {
        "id": "Izq4uk6tYIMW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "intents = {\n",
        "    \"greet\": [\"hello\", \"hi\", \"hey\"],\n",
        "    \"farewell\": [\"bye\", \"goodbye\", \"see you later\"],\n",
        "    \"search\": [\"find\", \"search\", \"look for\"],\n",
        "    # Add more intents as needed\n",
        "}\n",
        "\n",
        "entities = {\n",
        "    \"location\": [\"city\", \"town\", \"place\"],\n",
        "    \"date\": [\"today\", \"tomorrow\", \"next week\"],\n",
        "    # Add more entities as needed\n",
        "}\n",
        "\n",
        "def extract_intent(message):\n",
        "    for intent, keywords in intents.items():\n",
        "        if any(keyword in message.lower() for keyword in keywords):\n",
        "            return intent\n",
        "    return None\n",
        "\n",
        "def extract_entities(message):\n",
        "    extracted_entities = {}\n",
        "    for entity, keywords in entities.items():\n",
        "        for keyword in keywords:\n",
        "            if keyword in message.lower():\n",
        "                extracted_entities[entity] = keyword\n",
        "                break\n",
        "    return extracted_entities\n",
        "\n",
        "# Example usage:\n",
        "user_message = \"Hi, can you find a restaurant in New York for tomorrow?\"\n",
        "user_intent = extract_intent(user_message)\n",
        "user_entities = extract_entities(user_message)\n",
        "\n",
        "print(\"User Intent:\", user_intent)\n",
        "print(\"User Entities:\", user_entities)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysQJ0vxpJ3mk",
        "outputId": "87a4dcee-6b47-4490-b2ce-3a7c40253aa3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User Intent: greet\n",
            "User Entities: {'date': 'tomorrow'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dialogue Flows"
      ],
      "metadata": {
        "id": "_HKVfkBhYNJd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def greet_user():\n",
        "    print(\"Welcome to our chatbot! How can I assist you today?\")\n",
        "\n",
        "def handle_user_input(user_input):\n",
        "    if \"search\" in user_input:\n",
        "        search_topic(user_input)\n",
        "    elif \"order\" in user_input:\n",
        "        place_order(user_input)\n",
        "    else:\n",
        "        handle_unknown_input()\n",
        "\n",
        "def search_topic(user_input):\n",
        "    print(\"Sure, let me find some information on that topic.\")\n",
        "\n",
        "def place_order(user_input):\n",
        "    print(\"Great! Let's proceed with placing your order.\")\n",
        "\n",
        "def handle_unknown_input():\n",
        "    print(\"I'm sorry, I didn't understand that. Can you please rephrase your request?\")\n",
        "\n",
        "# Example dialogue flow:\n",
        "greet_user()\n",
        "user_input = input(\"How can I help you today? \")\n",
        "handle_user_input(user_input)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJIekzhOJ3pU",
        "outputId": "20a24979-ffe7-4278-f848-e7b334e099b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to our chatbot! How can I assist you today?\n",
            "How can I help you today? search\n",
            "Sure, let me find some information on that topic.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### User Input Handling"
      ],
      "metadata": {
        "id": "cDQikhgXYb8P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Define rules for handling user input\n",
        "patterns = {\n",
        "    'greet': re.compile(r'hello|hi|hey'),\n",
        "    'farewell': re.compile(r'bye|goodbye'),\n",
        "    'search': re.compile(r'find (.+?) (in|at|near) (.+?)'),\n",
        "}\n",
        "\n",
        "# Define responses for each intent\n",
        "responses = {\n",
        "    'greet': \"Hello! How can I assist you today?\",\n",
        "    'farewell': \"Goodbye! Have a great day!\",\n",
        "    'search': \"Searching for {object} near {location}...\",\n",
        "}\n",
        "\n",
        "# Function to handle user input and generate response\n",
        "def handle_user_input(user_input):\n",
        "    for intent, pattern in patterns.items():\n",
        "        match = re.search(pattern, user_input.lower())\n",
        "        if match:\n",
        "            if intent == 'search':\n",
        "                object_to_find = match.group(1)\n",
        "                location = match.group(3)\n",
        "                response = responses[intent].format(object=object_to_find, location=location)\n",
        "            else:\n",
        "                response = responses[intent]\n",
        "            return response\n",
        "    return \"Sorry, I didn't understand that.\"\n",
        "\n",
        "# Example usage:\n",
        "user_input = \"Hi, can you find a restaurant near Central Park?\"\n",
        "response = handle_user_input(user_input)\n",
        "print(\"Chatbot Response:\", response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYMTZbmdJ3vF",
        "outputId": "fc9a4a8b-0c89-4b55-8047-417e884c7eba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chatbot Response: Hello! How can I assist you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Rule-Based Decision Making"
      ],
      "metadata": {
        "id": "p4IifRLnZabc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def decide_response(user_input):\n",
        "    # Decision tree/rule set to determine responses based on user inputs\n",
        "    if \"hello\" in user_input:\n",
        "        return \"Hi there! How can I assist you today?\"\n",
        "    elif \"weather\" in user_input:\n",
        "        return \"The weather forecast for today is sunny.\"\n",
        "    elif \"news\" in user_input:\n",
        "        return \"Here are the latest headlines: ...\"\n",
        "    else:\n",
        "        return \"I'm sorry, I didn't understand. Could you please rephrase?\"\n",
        "\n",
        "# Example usage:\n",
        "user_input = input(\"User: \")\n",
        "response = decide_response(user_input)\n",
        "print(\"Chatbot:\", response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fs9_fMdjJ3x1",
        "outputId": "bfb7ffe1-1f5d-4376-967f-b7edc457e305"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: weather\n",
            "Chatbot: The weather forecast for today is sunny.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Contextual awareness"
      ],
      "metadata": {
        "id": "NYTNVElHZh_u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Chatbot:\n",
        "    def __init__(self):\n",
        "        self.context = {}  # Initialize an empty context dictionary\n",
        "\n",
        "    def process_message(self, message):\n",
        "        # Update context based on message content\n",
        "        self.update_context(message)\n",
        "        # Generate response based on context\n",
        "        response = self.generate_response()\n",
        "        return response\n",
        "\n",
        "    def update_context(self, message):\n",
        "        # Example: Extract relevant entities from the message and update context\n",
        "        entities = extract_entities(message)\n",
        "        for entity, value in entities.items():\n",
        "            self.context[entity] = value\n",
        "\n",
        "    def generate_response(self):\n",
        "        # Example: Use context to generate a contextually relevant response\n",
        "        if \"location\" in self.context:\n",
        "            response = f\"Sure, I can help you find restaurants in {self.context['location']}.\"\n",
        "        else:\n",
        "            response = \"How can I assist you today?\"\n",
        "        return response\n",
        "\n",
        "# Example usage:\n",
        "chatbot = Chatbot()\n",
        "user_message1 = \"Can you find a restaurant nearby?\"\n",
        "response1 = chatbot.process_message(user_message1)\n",
        "print(\"Response:\", response1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSraxKfmJ30j",
        "outputId": "849417a4-d75f-422b-ed81-a1c6aca41235"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response: How can I assist you today?\n",
            "Response: Sure, I can help you find restaurants in about Italian restaurants?.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_message2 = \"What about Italian restaurants?\"\n",
        "response2 = chatbot.process_message(user_message2)\n",
        "print(\"Response:\", response2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JAxJA3eJ33J",
        "outputId": "fef50a5b-e2a0-474e-caf1-9a4bcda69ff5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response: Sure, I can help you find restaurants in about Italian restaurants?.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dynamic Responses"
      ],
      "metadata": {
        "id": "dAf5vgxNZnQ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define greetings and farewells\n",
        "greetings = [\"hello\", \"hi\", \"hey\"]\n",
        "farewells = [\"bye\", \"goodbye\", \"see you later\"]\n",
        "\n",
        "# Define knowledge base (replace with your data)\n",
        "knowledge_base = {\n",
        "    \"weather\": \"It's a beautiful day!\",\n",
        "    \"time\": \"The current time is 10:30 AM.\",\n",
        "    \"who are you\": \"I am a friendly chatbot!\",\n",
        "}\n",
        "\n",
        "# Function to check for greetings and farewells\n",
        "def is_greeting(user_input):\n",
        "  return user_input.lower() in greetings\n",
        "\n",
        "def is_farewell(user_input):\n",
        "  return user_input.lower() in farewells\n",
        "\n",
        "# Function to handle user input\n",
        "def handle_input(user_input):\n",
        "  if is_greeting(user_input):\n",
        "    return f\"Hi! How can I help you today?\"\n",
        "  elif is_farewell(user_input):\n",
        "    return \"Bye! Have a great day!\"\n",
        "  else:\n",
        "    # Check knowledge base for predefined responses\n",
        "    if user_input.lower() in knowledge_base:\n",
        "      return knowledge_base[user_input.lower()]\n",
        "    else:\n",
        "      return \"Sorry, I don't understand. Try asking something else!\"\n",
        "\n",
        "# Main loop for conversation\n",
        "while True:\n",
        "  user_input = input(\"You: \")\n",
        "  response = handle_input(user_input)\n",
        "  print(\"Chatbot:\", response)\n",
        "  if is_farewell(user_input):\n",
        "    break  # Exit the loop on farewell message"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wveUP56pJ388",
        "outputId": "528408c9-0bcf-4427-e92c-a84ba1489c0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You: time\n",
            "Chatbot: The current time is 10:30 AM.\n",
            "You: weather\n",
            "Chatbot: It's a beautiful day!\n",
            "You: farewell\n",
            "Chatbot: Sorry, I don't understand. Try asking something else!\n",
            "You: bye\n",
            "Chatbot: Bye! Have a great day!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (NLU) Integration"
      ],
      "metadata": {
        "id": "HdD9K8v-Z9Sd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install NLU\n",
        "!pip install nlu pyspark johnsnowlabs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OozZuvUw8Png",
        "outputId": "ea228d22-356e-433b-c46a-21be97213802"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nlu in /usr/local/lib/python3.10/dist-packages (5.3.0)\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.4.0)\n",
            "Requirement already satisfied: johnsnowlabs in /usr/local/lib/python3.10/dist-packages (5.3.4)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.10/dist-packages (from nlu) (0.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from nlu) (1.23.5)\n",
            "Requirement already satisfied: pandas>=1.3.5 in /usr/local/lib/python3.10/dist-packages (from nlu) (2.0.3)\n",
            "Requirement already satisfied: pyarrow>=0.16.0 in /usr/local/lib/python3.10/dist-packages (from nlu) (14.0.2)\n",
            "Requirement already satisfied: spark-nlp>=5.0.2 in /usr/local/lib/python3.10/dist-packages (from nlu) (5.3.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.10/dist-packages (from johnsnowlabs) (1.34.93)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from johnsnowlabs) (0.4.6)\n",
            "Requirement already satisfied: databricks-api in /usr/local/lib/python3.10/dist-packages (from johnsnowlabs) (0.9.0)\n",
            "Requirement already satisfied: pydantic==1.10.11 in /usr/local/lib/python3.10/dist-packages (from johnsnowlabs) (1.10.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from johnsnowlabs) (2.31.0)\n",
            "Requirement already satisfied: spark-nlp-display==5.0 in /usr/local/lib/python3.10/dist-packages (from johnsnowlabs) (5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic==1.10.11->johnsnowlabs) (4.11.0)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from spark-nlp-display==5.0->johnsnowlabs) (7.34.0)\n",
            "Requirement already satisfied: svgwrite==1.4 in /usr/local/lib/python3.10/dist-packages (from spark-nlp-display==5.0->johnsnowlabs) (1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.5->nlu) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.5->nlu) (2022.7.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.5->nlu) (2024.1)\n",
            "Requirement already satisfied: botocore<1.35.0,>=1.34.93 in /usr/local/lib/python3.10/dist-packages (from boto3->johnsnowlabs) (1.34.93)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3->johnsnowlabs) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from boto3->johnsnowlabs) (0.10.1)\n",
            "Requirement already satisfied: databricks-cli in /usr/local/lib/python3.10/dist-packages (from databricks-api->johnsnowlabs) (0.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->johnsnowlabs) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->johnsnowlabs) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->johnsnowlabs) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->johnsnowlabs) (2024.2.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.3.5->nlu) (1.16.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from databricks-cli->databricks-api->johnsnowlabs) (8.1.7)\n",
            "Requirement already satisfied: pyjwt>=1.7.0 in /usr/lib/python3/dist-packages (from databricks-cli->databricks-api->johnsnowlabs) (2.3.0)\n",
            "Requirement already satisfied: oauthlib>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from databricks-cli->databricks-api->johnsnowlabs) (3.2.2)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from databricks-cli->databricks-api->johnsnowlabs) (0.9.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->spark-nlp-display==5.0->johnsnowlabs) (67.7.2)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython->spark-nlp-display==5.0->johnsnowlabs) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->spark-nlp-display==5.0->johnsnowlabs) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->spark-nlp-display==5.0->johnsnowlabs) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->spark-nlp-display==5.0->johnsnowlabs) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->spark-nlp-display==5.0->johnsnowlabs) (3.0.28)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->spark-nlp-display==5.0->johnsnowlabs) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->spark-nlp-display==5.0->johnsnowlabs) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->spark-nlp-display==5.0->johnsnowlabs) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->spark-nlp-display==5.0->johnsnowlabs) (4.9.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->spark-nlp-display==5.0->johnsnowlabs) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->spark-nlp-display==5.0->johnsnowlabs) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->spark-nlp-display==5.0->johnsnowlabs) (0.2.13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a model (e.g., sentiment analysis)\n",
        "import nlu\n",
        "model = nlu.load(\"sentiment\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1nXsuYp8hXQ",
        "outputId": "073befae-9ea3-40a0-8f43-78c8e19bd014"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning::Spark Session already created, some configs may not take.\n",
            "sentimentdl_glove_imdb download started this may take some time.\n",
            "Approximate size to download 8.7 MB\n",
            "[OK!]\n",
            "glove_100d download started this may take some time.\n",
            "Approximate size to download 145.3 MB\n",
            "[OK!]\n",
            "sentence_detector_dl download started this may take some time.\n",
            "Approximate size to download 354.6 KB\n",
            "[OK!]\n",
            "Warning::Spark Session already created, some configs may not take.\n",
            "                       sentence  \\\n",
            "0  This is a positive sentence.   \n",
            "\n",
            "                        sentence_embedding_converter sentiment  \\\n",
            "0  [-0.1118033230304718, 0.2755109965801239, 0.33...       pos   \n",
            "\n",
            "  sentiment_confidence                               word_embedding_glove  \n",
            "0              0.99999  [[-0.570580005645752, 0.44183000922203064, 0.7...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on text data\n",
        "result = model.predict(\"This is a good product.\")\n",
        "print(result[\"sentiment\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWdr8gyF94np",
        "outputId": "c7b39643-5d69-4045-8661-c9d5f3b3e682"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    pos\n",
            "Name: sentiment, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on text data\n",
        "result = model.predict(\"This is a bad movie.\")\n",
        "print(result[\"sentiment\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "raWDHUtm-Gxv",
        "outputId": "384a5b18-1322-4564-8f6a-f21fa7527587"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    neg\n",
            "Name: sentiment, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Machine Learning Augmentation"
      ],
      "metadata": {
        "id": "omp2QPWaaW5H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Install scikit-learn\n",
        "! pip install scikit-learn"
      ],
      "metadata": {
        "id": "afNmeNfXD94h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Prepare Training Data\n",
        "import csv\n",
        "\n",
        "data = [\n",
        "    [\"message\", \"intent\"],\n",
        "    [\"Hello!\", \"greet\"],\n",
        "    [\"Hi there!\", \"greet\"],\n",
        "    [\"Can I book a table for two?\", \"book_table\"],\n",
        "    [\"I want to make a restaurant reservation\", \"book_table\"]\n",
        "]\n",
        "\n",
        "# Write the data to a CSV file\n",
        "with open('training_data.csv', 'w', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerows(data)\n",
        "\n",
        "print(\"Data has been saved to training_data.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "619xVVzA5fcH",
        "outputId": "76aa9d55-d91e-4348-be90-5f484b9eda2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data has been saved to training_data.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Train Supervised Learning Model\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# Load training data\n",
        "training_data = pd.read_csv(\"/content/training_data.csv\")\n",
        "\n",
        "# Define features and target\n",
        "X = training_data[\"message\"]\n",
        "y = training_data[\"intent\"]\n",
        "\n",
        "# Create a pipeline with CountVectorizer and LogisticRegression\n",
        "pipeline = make_pipeline(CountVectorizer(), LogisticRegression())\n",
        "\n",
        "# Train the model\n",
        "pipeline.fit(X, y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "8G-P3XQY3BAf",
        "outputId": "b758ee7a-bb9a-413f-e4fb-1554b058b960"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('countvectorizer', CountVectorizer()),\n",
              "                ('logisticregression', LogisticRegression())])"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;countvectorizer&#x27;, CountVectorizer()),\n",
              "                (&#x27;logisticregression&#x27;, LogisticRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;countvectorizer&#x27;, CountVectorizer()),\n",
              "                (&#x27;logisticregression&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Define Rule-Based Responses\n",
        "def greet():\n",
        "    return \"Hello! How can I assist you today?\"\n",
        "\n",
        "def book_table():\n",
        "    return \"Sure, I've booked a table for two. What time would you like to book?\"\n",
        "\n",
        "# Define rules for mapping intents to functions\n",
        "intent_to_function = {\n",
        "    \"greet\": greet,\n",
        "    \"book_table\": book_table,\n",
        "}\n",
        "\n",
        "# Step 4: Integrate ML into Chatbot\n",
        "def predict_intent(message):\n",
        "    # Use the trained model to predict the intent\n",
        "    predicted_intent = pipeline.predict([message])[0]\n",
        "\n",
        "    # Get the confidence score of the prediction\n",
        "    confidence_score = pipeline.predict_proba([message]).max()\n",
        "\n",
        "    return predicted_intent, confidence_score\n",
        "\n",
        "def process_message_with_ml(user_message):\n",
        "    # Predict intent using supervised learning model\n",
        "    predicted_intent, confidence_score = predict_intent(user_message)\n",
        "\n",
        "    # If confidence score is below threshold, fallback to rule-based processing\n",
        "    if confidence_score < 0.4:\n",
        "        response = process_message_with_rules(user_message)\n",
        "    else:\n",
        "        # Determine function to execute based on predicted intent\n",
        "        if predicted_intent in intent_to_function:\n",
        "            response = intent_to_function[predicted_intent]()\n",
        "        else:\n",
        "            response = \"Sorry, I'm not sure how to respond to that.\"\n",
        "\n",
        "    return response\n",
        "\n",
        "def process_message_with_rules(user_message):\n",
        "    # Define rule-based processing logic here\n",
        "    # For simplicity, we'll just return a default response\n",
        "    return \"I'm sorry, I couldn't understand your request. Please try again.\"\n",
        "\n",
        "# Example usage:\n",
        "user_message = \"Can I book a table for two?\"\n",
        "response = process_message_with_ml(user_message)\n",
        "print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulKtNf-Y6Ovp",
        "outputId": "0d82b174-0b98-47e6-b405-0dde50943775"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sure, I've booked a table for two. What time would you like to book?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aDZs546Yadp-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}