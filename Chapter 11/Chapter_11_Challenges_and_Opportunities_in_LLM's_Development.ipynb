{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### API"
      ],
      "metadata": {
        "id": "dbLZ64AcRjEs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TF97KgixWLcN"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "api_key = userdata.get('api_key')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exploring Model Capabilities Using OpenAI GPT API"
      ],
      "metadata": {
        "id": "EFtED9D9hxqa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "def initialize_client(api_key):\n",
        "    \"\"\"\n",
        "    Initialize the OpenAI client with the provided API key.\n",
        "\n",
        "    Parameters:\n",
        "    - api_key (str): The API key for accessing OpenAI services.\n",
        "\n",
        "    Returns:\n",
        "    - OpenAI: The initialized OpenAI client.\n",
        "    \"\"\"\n",
        "    return OpenAI(api_key=api_key)\n",
        "\n",
        "def generate_completion(client, model, prompt, store=False):\n",
        "    \"\"\"\n",
        "    Generate a chat completion using the specified model and prompt.\n",
        "\n",
        "    Parameters:\n",
        "    - client (OpenAI): The initialized OpenAI client.\n",
        "    - model (str): The model name to use for the completion.\n",
        "    - prompt (str): The prompt content for generating the response.\n",
        "    - store (bool): Whether to store the conversation history (optional).\n",
        "\n",
        "    Returns:\n",
        "    - str: The content of the generated message.\n",
        "    \"\"\"\n",
        "    completion = client.chat.completions.create(\n",
        "        model=model,\n",
        "        store=store,\n",
        "        max_tokens=100,\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "    return completion.choices[0].message.content\n",
        "\n",
        "def main():\n",
        "\n",
        "    # Initialize the client\n",
        "    client = initialize_client(api_key)\n",
        "\n",
        "    # Define the model and prompt\n",
        "    model = \"gpt-4o-mini\"\n",
        "    prompt = f\"Explain Model Capabilities {model} in bullet points\"\n",
        "\n",
        "    # Generate and print the completion\n",
        "    response = generate_completion(client, model, prompt)\n",
        "    print(response)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tb0O0IV-fVxU",
        "outputId": "e85dbfb7-5a2c-4725-e1de-cc13e31d20c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPT-4o-mini is designed with several specific capabilities. While exact details can vary based on implementation and updates, here are some generalized capabilities you might find in models like GPT-4o-mini:\n",
            "\n",
            "- **Language Understanding**: Proficient in understanding and generating human language across various contexts.\n",
            "\n",
            "- **Conversational Abilities**: Capable of engaging in natural, flowing conversations with users, mimicking human-like dialogue.\n",
            "\n",
            "- **Context Awareness**: Maintains context throughout interactions, allowing for coherent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implementing Guardrails to Filter Offensive Content"
      ],
      "metadata": {
        "id": "bHF0PJGxj1UV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "def contains_offensive_content(message, offensive_keywords):\n",
        "    \"\"\"\n",
        "    Check if the message contains any offensive content based on predefined keywords.\n",
        "\n",
        "    Parameters:\n",
        "    - message (str): The message content to check.\n",
        "    - offensive_keywords (list): A list of offensive keywords.\n",
        "\n",
        "    Returns:\n",
        "    - bool: True if offensive content is found, otherwise False.\n",
        "    \"\"\"\n",
        "    message_lower = message.lower()\n",
        "    for keyword in offensive_keywords:\n",
        "        if keyword in message_lower:\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "def handle_message(client, user_message, offensive_keywords):\n",
        "    \"\"\"\n",
        "    Handle the user message by checking for offensive content and interacting with the model.\n",
        "\n",
        "    Parameters:\n",
        "    - client (OpenAI): The OpenAI client instance.\n",
        "    - user_message (str): The message from the user.\n",
        "    - offensive_keywords (list): A list of offensive keywords.\n",
        "\n",
        "    Returns:\n",
        "    - str: The response from the model or a warning message.\n",
        "    \"\"\"\n",
        "    # Check for offensive content\n",
        "    if contains_offensive_content(user_message, offensive_keywords):\n",
        "        return \"Your message contains content that violates our guidelines. Please rephrase your message.\"\n",
        "\n",
        "    # Proceed with generating a response\n",
        "    completion = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        store=True,\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": user_message}\n",
        "        ]\n",
        "    )\n",
        "    return completion.choices[0].message.content\n",
        "\n",
        "def main():\n",
        "    client = OpenAI(api_key=api_key)\n",
        "\n",
        "    offensive_keywords = [\"ugly\", \"fat\", \"black\"]\n",
        "\n",
        "    print(\"Chatbot: Hello! How can I assist you today?\")\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() in [\"exit\", \"quit\"]:\n",
        "            print(\"Chatbot: Goodbye!\")\n",
        "            break\n",
        "\n",
        "        response = handle_message(client, user_input, offensive_keywords)\n",
        "        print(f\"Chatbot: {response}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTnSqMv7jcdt",
        "outputId": "cb22c25c-99c1-4239-fb8d-47a8b24a9346"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chatbot: Hello! How can I assist you today?\n",
            "You: you are ugly\n",
            "Chatbot: Your message contains content that violates our guidelines. Please rephrase your message.\n",
            "You: you are good\n",
            "Chatbot: Thank you! I'm here to help, so if you have any questions or need assistance with something, just let me know!\n",
            "You: exit\n",
            "Chatbot: Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building a Language Translation Chatbot with OpenAI"
      ],
      "metadata": {
        "id": "lnjM3UVPljEW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "def detect_target_language(user_message):\n",
        "    \"\"\"\n",
        "    Detect the target language from the user message.\n",
        "\n",
        "    Parameters:\n",
        "    - user_message (str): The message from the user requesting a translation.\n",
        "\n",
        "    Returns:\n",
        "    - tuple: A tuple containing the text to translate and the target language.\n",
        "    \"\"\"\n",
        "    if \"translate to\" in user_message.lower():\n",
        "        parts = user_message.lower().split(\"translate to\")\n",
        "        text_to_translate = parts[0].strip()\n",
        "        target_language = parts[1].strip()\n",
        "        return text_to_translate, target_language\n",
        "    return None, None\n",
        "\n",
        "def translate_text(client, text, target_language):\n",
        "    \"\"\"\n",
        "    Translate the given text into the target language using the OpenAI model.\n",
        "\n",
        "    Parameters:\n",
        "    - client (OpenAI): The OpenAI client instance.\n",
        "    - text (str): The text to translate.\n",
        "    - target_language (str): The target language for translation.\n",
        "\n",
        "    Returns:\n",
        "    - str: The translated text.\n",
        "    \"\"\"\n",
        "    prompt = f\"Translate the following text to {target_language}:\\n{text}\"\n",
        "    completion = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        store=True,\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "    return completion.choices[0].message.content\n",
        "\n",
        "def handle_message(client, user_message):\n",
        "    \"\"\"\n",
        "    Handle the user message by checking for translation requests and interacting with the model.\n",
        "\n",
        "    Parameters:\n",
        "    - client (OpenAI): The OpenAI client instance.\n",
        "    - user_message (str): The message from the user.\n",
        "\n",
        "    Returns:\n",
        "    - str: The response from the model or a warning message.\n",
        "    \"\"\"\n",
        "    # Check for translation request\n",
        "    text, target_language = detect_target_language(user_message)\n",
        "    if text and target_language:\n",
        "        return translate_text(client, text, target_language)\n",
        "\n",
        "    # If not a translation request, handle as normal conversation\n",
        "    completion = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        store=True,\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": user_message}\n",
        "        ]\n",
        "    )\n",
        "    return completion.choices[0].message.content\n",
        "\n",
        "def main():\n",
        "\n",
        "    client = OpenAI(api_key=api_key)\n",
        "\n",
        "    print(\"Translation Chatbot: Hello! You can ask me to translate text by saying 'Translate to [language]'.\")\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() in [\"exit\", \"quit\"]:\n",
        "            print(\"Translation Chatbot: Goodbye!\")\n",
        "            break\n",
        "\n",
        "        response = handle_message(client, user_input)\n",
        "        print(f\"Translation Chatbot: {response}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yKmcpLMjxv8",
        "outputId": "a0de95f0-29b9-4e1e-e128-061dd0e67880"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translation Chatbot: Hello! You can ask me to translate text by saying 'Translate to [language]'.\n",
            "You: How are you Translate to Japanese\n",
            "Translation Chatbot: The translation of \"how are you\" in Japanese is \"お元気ですか？\" (Ogenki desu ka?).\n",
            "You: How are you Translate to Tamil\n",
            "Translation Chatbot: The translation of \"how are you\" in Tamil is \"நீங்கள் எப்படி இருக்கிறீர்கள்?\" (nīṅkaḷ eppaṭi irukkiṟīrkaḷ?).\n",
            "You: exit\n",
            "Translation Chatbot: Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Medical Assistant Chatbot with Gemini"
      ],
      "metadata": {
        "id": "ddQwIWHpocO8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "def generate_medical_answer(api_key, question):\n",
        "    \"\"\"\n",
        "    Generates a medical answer based on the user's query using the Generative AI model.\n",
        "\n",
        "    Parameters:\n",
        "    - api_key (str): The API key for authenticating with the Generative AI service.\n",
        "    - question (str): The medical question to be answered.\n",
        "\n",
        "    Returns:\n",
        "    - str: The generated answer.\n",
        "    \"\"\"\n",
        "    # Configure the Generative AI API with the provided API key\n",
        "    genai.configure(api_key=api_key)\n",
        "\n",
        "    # Initialize the generative model\n",
        "    model = genai.GenerativeModel('gemini-1.5-flash')  # You can use other Gemini models as well\n",
        "\n",
        "    # Generate a medical response based on the user's question\n",
        "    response = model.generate_content(question,\n",
        "                                      generation_config=genai.GenerationConfig(max_output_tokens=150,\n",
        "                                                                               temperature=0.3))  # More focused and factual answers\n",
        "\n",
        "    # Extract and return the generated response from the model\n",
        "    return response.text\n",
        "\n",
        "def medical_assistant_chat(api_key):\n",
        "    \"\"\"\n",
        "    Simulates a medical assistant chatbot that answers medical questions.\n",
        "    The conversation continues until the user types 'exit'.\n",
        "\n",
        "    Parameters:\n",
        "    - api_key (str): The API key for authenticating with the Generative AI service.\n",
        "    \"\"\"\n",
        "    print(\"Hello! I am your Medical Assistant. Ask me anything about medical topics.\")\n",
        "    print(\"Type 'exit' anytime to end the chat.\\n\")\n",
        "\n",
        "    while True:\n",
        "        # Get user's medical question\n",
        "        question = input(\"You: \")\n",
        "\n",
        "        # Check for exit condition\n",
        "        if question.lower() == 'exit':\n",
        "            print(\"Goodbye! Stay healthy.\")\n",
        "            break\n",
        "\n",
        "        # Get the medical answer\n",
        "        answer = generate_medical_answer(api_key, question)\n",
        "\n",
        "        # Print the answer\n",
        "        print(\"Medical Assistant: \", answer)\n",
        "\n",
        "# Example usage\n",
        "api_key = userdata.get('GOOGLE_API_KEY')  # Fetch the API key from your secure storage\n",
        "medical_assistant_chat(api_key)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "YvAON6LCobcO",
        "outputId": "6df6940e-f736-4d7f-fdb3-472cd8080a6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello! I am your Medical Assistant. Ask me anything about medical topics.\n",
            "Type 'exit' anytime to end the chat.\n",
            "\n",
            "You: What is the treatment for a common cold?\n",
            "Medical Assistant:  There's no cure for the common cold, which is caused by viruses.  Treatment focuses on relieving symptoms until the body fights off the infection.  This typically involves:\n",
            "\n",
            "* **Rest:**  This allows your body to focus its energy on fighting the virus.\n",
            "\n",
            "* **Hydration:** Drink plenty of fluids like water, clear broths, and herbal teas to prevent dehydration.\n",
            "\n",
            "* **Over-the-counter (OTC) medications:** These can help manage symptoms:\n",
            "    * **Pain relievers/fever reducers:** Acetaminophen (Tylenol) or ibuprofen (Advil, Motrin) can reduce fever and aches.  **Never give aspirin to children or teenagers.**\n",
            "    * **Decongestants:** These\n",
            "You: exit\n",
            "Goodbye! Stay healthy.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j9Ny_iGXobnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building Recipe Generator Based on Available Ingredients ChatBot"
      ],
      "metadata": {
        "id": "RgsoLO5BRQIe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "# Set up your OpenAI API key\n",
        "client = OpenAI(\n",
        "  api_key=api_key\n",
        ")\n",
        "\n",
        "def get_recipe(ingredients):\n",
        "    completion = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        store=True,\n",
        "        messages=[{\"role\": \"user\", \"content\": f\"I have {ingredients}. What can I cook?\"}]\n",
        "    )\n",
        "    return completion.choices[0].message.content\n",
        "\n",
        "def chat_bot():\n",
        "    print(\"Welcome to the Recipe Generator Bot! Ask for recipe suggestions or type 'exit' to end.\")\n",
        "    while True:\n",
        "        user_input = input(\"You: \").strip()\n",
        "\n",
        "        if user_input.lower() == 'exit':\n",
        "            print(\"Goodbye! Happy cooking!\")\n",
        "            break\n",
        "\n",
        "        # Handle QA and recipe generation\n",
        "        if \"what can i cook\" in user_input.lower():\n",
        "            ingredients = user_input.replace(\"what can i cook with\", \"\").strip()\n",
        "            if ingredients:\n",
        "                recipe = get_recipe(ingredients)\n",
        "                print(f\"Bot: You can cook {recipe}\")\n",
        "            else:\n",
        "                print(\"Bot: Please provide some ingredients!\")\n",
        "        else:\n",
        "            print(\"Bot: I'm sorry, I can only suggest recipes based on ingredients. Ask me what you can cook with a list of ingredients.\")\n",
        "\n",
        "\n",
        "# Start the chatbot\n",
        "chat_bot()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hssoXQudRRsa",
        "outputId": "1945d9e7-cb9d-4148-faa8-2e709a322932"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to the Recipe Generator Bot! Ask for recipe suggestions or type 'exit' to end.\n",
            "You: What can I cook with chicken, tomatoes, and potato?\n",
            "Bot: You can cook With chicken, tomatoes, and potatoes, you can make several delicious dishes. Here are a few ideas:\n",
            "\n",
            "1. **Chicken and Tomato Stew**:\n",
            "   - Sauté chopped onions and garlic in a pot.\n",
            "   - Add diced chicken and cook until browned.\n",
            "   - Add chopped tomatoes (fresh or canned), diced potatoes, and season with herbs (like basil or oregano), salt, and pepper.\n",
            "   - Simmer until the potatoes are tender and the chicken is cooked through.\n",
            "\n",
            "2. **Baked Chicken with Tomatoes and Potatoes**:\n",
            "   - Preheat the oven to 400°F (200°C).\n",
            "   - In a baking dish, place seasoned chicken pieces, halved potatoes, and chopped tomatoes.\n",
            "   - Drizzle with olive oil, add herbs like rosemary or thyme, and season with salt and pepper.\n",
            "   - Bake for about 40-50 minutes or until the chicken is cooked and the potatoes are tender.\n",
            "\n",
            "3. **Chicken, Tomato, and Potato Curry**:\n",
            "   - Sauté onions, garlic, and ginger in a pot.\n",
            "   - Add diced chicken and cook until browned.\n",
            "   - Stir in diced potatoes and chopped tomatoes, along with curry powder or paste.\n",
            "   - Add coconut milk or chicken broth and simmer until the potatoes are tender and the flavors meld.\n",
            "\n",
            "4. **One-Pan Chicken with Tomatoes and Potatoes**:\n",
            "   - In a large oven-safe skillet, heat oil and brown chicken pieces.\n",
            "   - Add diced potatoes and halved tomatoes around the chicken.\n",
            "   - Season with garlic, Italian herbs, salt, and pepper.\n",
            "   - Cover and cook on the stove for a few minutes, then transfer to the oven to bake until everything is cooked through.\n",
            "\n",
            "5. **Chicken and Potato Casserole with Tomato Sauce**:\n",
            "   - Layer sliced potatoes, cooked chicken (shredded or chopped), and tomato sauce in a baking dish.\n",
            "   - Season with cheese, breadcrumbs, and herbs.\n",
            "   - Bake until the top is golden and bubbly.\n",
            "\n",
            "Feel free to adjust the seasonings and cooking method according to your preferences! Enjoy your cooking!\n",
            "You: exit\n",
            "Goodbye! Happy cooking!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s1hbJZSPSm6V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}